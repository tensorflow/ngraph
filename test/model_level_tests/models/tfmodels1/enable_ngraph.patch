diff --git a/research/object_detection/metrics/coco_tools.py b/research/object_detection/metrics/coco_tools.py
index 71b747bc..cb117b75 100644
--- a/research/object_detection/metrics/coco_tools.py
+++ b/research/object_detection/metrics/coco_tools.py
@@ -115,7 +115,8 @@ class COCOWrapper(coco.COCO):
     if (set(annotation_img_ids) != (set(annotation_img_ids)
                                     & set(self.getImgIds()))):
       raise ValueError('Results do not correspond to current coco set')
-    results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])
+    #results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])
+    results.dataset['categories'] = self.dataset['categories']
     if self._detection_type == 'bbox':
       for idx, ann in enumerate(annotations):
         bb = ann['bbox']
diff --git a/research/object_detection/model_main.py b/research/object_detection/model_main.py
index 2082c848..a109c549 100644
--- a/research/object_detection/model_main.py
+++ b/research/object_detection/model_main.py
@@ -21,10 +21,14 @@ from __future__ import print_function
 from absl import flags
 
 import tensorflow as tf
+import ngraph_bridge
 
 from object_detection import model_hparams
 from object_detection import model_lib
 
+# Log output to console
+tf.logging.set_verbosity(tf.logging.INFO)
+
 flags.DEFINE_string(
     'model_dir', None, 'Path to output model directory '
     'where event and checkpoint files will be written.')
diff --git a/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config b/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config
index a80117b5..997debba 100644
--- a/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config
+++ b/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config
@@ -64,8 +64,8 @@ model {
             }
           }
           initializer {
-            truncated_normal_initializer {
-              stddev: 0.03
+            random_normal_initializer {
+              stddev: 0.01
               mean: 0.0
             }
           }
@@ -73,7 +73,7 @@ model {
             train: true,
             scale: true,
             center: true,
-            decay: 0.9997,
+            decay: 0.97,
             epsilon: 0.001,
           }
         }
@@ -91,8 +91,8 @@ model {
           }
         }
         initializer {
-          truncated_normal_initializer {
-            stddev: 0.03
+          random_normal_initializer {
+            stddev: 0.01
             mean: 0.0
           }
         }
@@ -100,7 +100,7 @@ model {
           train: true,
           scale: true,
           center: true,
-          decay: 0.9997,
+          decay: 0.97,
           epsilon: 0.001,
         }
       }
@@ -138,7 +138,7 @@ model {
 }
 
 train_config: {
-  batch_size: 24
+  batch_size: 64
   optimizer {
     rms_prop_optimizer: {
       learning_rate: {
@@ -153,8 +153,8 @@ train_config: {
       epsilon: 1.0
     }
   }
-  fine_tune_checkpoint: "PATH_TO_BE_CONFIGURED/model.ckpt"
-  from_detection_checkpoint: true
+  #fine_tune_checkpoint: "/localdisk/dataset/pretrained_models/mobilenet_v1/mobilenet_v1_1.0_224.ckpt"
++  from_detection_checkpoint: false
   # Note: The below line limits the training process to 200K steps, which we
   # empirically found to be sufficient enough to train the pets dataset. This
   # effectively bypasses the learning rate schedule (the learning rate will
@@ -172,16 +172,16 @@ train_config: {
 
 train_input_reader: {
   tf_record_input_reader {
-    input_path: "PATH_TO_BE_CONFIGURED/mscoco_train.record-?????-of-00100"
+    input_path: "/mnt/data/mscoco2014/tf_records_train/coco_train.record*"
   }
-  label_map_path: "PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt"
+  label_map_path: "object_detection/data/mscoco_label_map.pbtxt"
 }
 
 eval_config: {
   num_examples: 8000
   # Note: The below line limits the evaluation process to 10 evaluations.
   # Remove the below line to evaluate indefinitely.
-  max_evals: 10
+  max_evals: 1
 }
 
 eval_input_reader: {
